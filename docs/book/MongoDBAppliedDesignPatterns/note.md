MongoDB应用设计模式
==================

前言
------------------

本书可提供用户需要的MongoDB特性和姐姐商业应用上的问题。本书重点关注MongoDB具体实现中遇到的实践性问题，特别适合那些希望利用MongoDB来应对特定扩展性问题的开发者阅读。

尽管本书对大部分MongoDB特性有一个基本描述，但本书并不是一本关于MongoDB的入门书籍。

第一部分 设计模式
------------------

第1章 嵌入还是引用
------------------

关系型数据库中，为了满足第一范式，可能带来冗余，为了消除冗余，可能要增加表。它给插入和更新记录都带来了一定的复杂性。

更大的问题在于，从多张表中查询数据，需要进行join操作，而该操作会导致磁盘的随机寻道。如果只查询一行记录，寻址时间占到了整个数据读取时间的99%以上。

即便现代的数据库都采用了一些内存对象来缓存优化，但是join操作还是非常昂贵的。

为了减少join带来的性能影响，一些系统又被设计成满足第一范式的，从而带来了大量的冗余。

MongoDB有一个概念就是数据不必总是列成表格，基本上否决了传统数据库从第一范式开始进行标准化的操作。

MongoDB即允许采用嵌入的方式存储文档，也可以按照标准化的方式（引用）存储文档：

嵌入的方式：

```
{
    "_id":3,
    "name":"Jenny",
    "zip_code":"01209",
    "numbers":["555-333-3456", "555-334-3411"]
}
```
标准化的方式（引用）：
```
// 联系人文档：
{
    "_id":3,
    "name":"Jenny",
    "zip_code":"01209"
}
// 电话号码文档：
{"contact_id":3, "number":"555-333-3456"}
{"contact_id":3, "number":"555-334-3411"}
```

嵌入模式：

- 可以支持一对多关系
- 希望保持数据的原子性和独立性
- 提供最好的性能和数据完整性保证

引用模式：

- 将用户数据模型标准化到多个容器，将会提升执行查询的灵活性，从而获得更好的性能。
- 有十分高或者无法预测的引数的一对多关系时。举例来说，一个拥有大量读者参与度的流行博客中，某个博客文章可能有成百上千的评论。如果采用嵌入方式就会带来明显的损失：
    - 文档越大，使用的内存就越大
    - 增长的文档最终必须拷贝到更大的空间中。
    - MongoDB文档最大不能超过16MB。

如何选择：

- 如果应用程序的查询模式是常见的，并且倾向于采用一种方式访问数据，那么嵌入式的途径就可以很好的工作。如果应用程序可能采用多种方式查询数据，或者您无法预计数据查询的模式，那么采用更“标准化”（引用）的方式可能更好。

多对多关系：

- 采用引用的方式，会导致查询过程较复杂
- 采用嵌入的方式，会导致更新的时候会导致需要更新所有潜入了该对象的文档的信息。
- 建议：采用折中的方式，嵌入_id的列表，而不是嵌入完整的文档。

总的来说，使用哪种方式取决于应用程序的访问方式，在MongoDB中很少有类似关系型数据库中所必须遵循的规则。灵活地使用MongoDB所提供的模式设计将有助于更好地使用这个强大的非关系型数据库。

第2章 多态模式
------------------

当集合中所有文档的结构都是类似的，但不是完全相同的时候，我们称为多态模式。

### 多态模式支持面向对象编程

如果要在关系型数据库中使用关系表来存储内容，可能遇到下面的问题：

- 单一表模型：单独的表包含所有的内容，但是不是所有的行都包含所有的列，存在空间浪费。
- 具体表模型：如果为不同的对象创建不同的表，那么查询的时候就要查询所有这些对象，变得复杂。
- 多态模型：采用引用的方式，可以减少浪费，但是需要联合查询。

如果使用MongoDB，可以将稍有差异的对象存储在一起，形成一个集合，不会产生存储空间浪费，而且查询语句和单一表模型一样简单，并具有具体表模型一样的效率。

### 多态模式使得模式进化成为可能

如果修改关系型数据库表，需要用到`ALTER TABLE`，但是效率很低。用MongoDB，效率一样很低。

但是可以通过在前台代码中使用设置默认值的代码（`node.setdefault('short_description', '')`），然后在后台，一部分一部分地修改数据，而不是对整个数据集修改数据结构的方式来缓解这个问题。

#### BSON的存储效率

MongoDB有一个主要的缺点时缺乏强制模式，这就是存储效率。主要表现在每一个文档都要存储字段的名字和类型。

为了减轻存储的压力，应该采用较短的字段名取代较长的字段名。但是这样做使得在shell中直接查看数据库变得困难。

一种改进存储效率的方法是使用MongoDB的对象-文档映射（object-document mapper，ODM），如Python中的MongoEngine、MongoKit和Ming。

### 多态模式支持半结构域数据

除了使用面向对象的多态模式来支持不同记录（行）之间存在差异字段（列）的模式之外，还可以使用一个通用的属性数组来表示一些不确定的项，并可以通过建立索引来加速查询。

第3章 模仿事务行为
------------------

### 一致性的有关方法

如果是针对单行数据的操作，本身就是原子级的，但并非所有的操作都是单行数据操作，比如：

- 情况1：一对多数据的删除，不仅要删除“一”还要删除“多”。
- 情况2：类似一种数据冗余，删除一行数据的时候，可能要修改另一个统计值（比如统计值是由删除的一行数据的一些字段组成的）。
- 情况3：进出互补的操作，如银行转账操作，出账和入账必须保持事务性。

一般的关系型数据库采用两段式的多状态事务进行提交，不适应分布式的场景。

### 混合文档

针对情况1：

当存在一对多的数据的时候，如果使用关系型数据库的设计方法，通常是设计成两张表，在发生删除操作的时候，包在一个事务中。如果支持级联约束，可以仅删除“一”，可同时删除“多”，但实际上在数据库内部仍然用到了事务。

如果在MongoDB中，如果采用类似关系型数据库的方法进行设计，则同样面临事务的问题，在遭遇意外的时候，将会出现部分数据未删除的情况。

要想保持原子性，可以将“一对多”关系存在单行数据中。

### 使用复杂更新

针对情况2：

可以使用MongoDB的原子更新操作，同时检查返回值来检查更新操作是否真正成功。

如果某个对象在进行原子更新操作的时候，执行失败了，说明其他人已经删除了该条目，则此时就不进行更新操作了，而是将它放进数组中。

### 使用补偿来优化更新

针对情况3：

创建一个“事务”集合来包含所有未完成的转账状态：

- 如果超时，任何位于“new”状态的事务将回滚。
- 任何位于“committed”状态的事务最终将被撤销。
- 任何位于“rollback”状态的事务最终将回滚。

这个模型包含一组方法：

- prepare_transfer：将事务对象放进事务列表中，然后完成实际的数据修改，并将事务ID也放进具体的数据中。
    - 源账户和目标账户存储了一个挂起的事务列表。以便可以在账户文档中追踪查看特定的事务ID是否处于挂起状态。
    - 事务本身必须在特定时间窗口中完成。如果没有完成，定期进程将回滚未完成的事务，或者根据该事务的最终状态来提交。这将处理应用程序或数据库在事务执行过程中崩溃的情形。
- commit_transfer：将事务的状态从new原子更新为commit。如果更新成功，该事务将退役，甚至在更新后立即发生崩溃。
- retire_transcation：退役一个事务的方法。从具体的数据中将事务ID移除，从事务列表中移除事务对象。同时这个方法是幂等的，可以多次重复操作。
- cleanup_transcation：对于状态为commit的事务对象，执行`retire_transcation`，对超时完成的事务对象，标记状态为rollback，对于标记为状态为rollback的对象，执行`rollback_transfer`方法。
- rollback_transfer：执行回滚操作。从具体的数据中，执行数据修改，调整为修改前的数值，将事务ID从具体的数据中移除，将事务对象从事务列表中移除。

第二部分 应用实例
------------------

第4章 运营智能
------------------

### 存储日志数据

#### 模式设计

- 仅将必要的内容存储进日志。
- 注意日志内容的格式，比如充分利用BSON格式的内置类型。

#### 操作

##### 插入日志记录

事件日志系统需要主要考虑如下性能指标：

- 可以支持每秒多少次插入操作，这将限制事件的吞吐量。
- 该系统如何管理事件数据的增长，特别在插入活动时的增长。

通过调整MongoDB的Write Concern，可以在存入数据库的重要性和插入速度之间及进行平衡。通过`db.events.insert(event, w=1)`、`db.events.insert(event, w=2)`、`db.events.insert(event, j=True)`、`db.events.insert(event, j=True, w=2)`等选项来控制这个平衡。

##### 批量插入

可以使用`insert()`函数一次传递多个事件。如果正在进行一个批量插入并遇到错误（或者是网络中断，或者是唯一性冲突），应用程序需要处理这种部分批量插入的可能性。如果在某些特殊情形下不在意丢失一些插入数据，可以为插入增加一个`continue_on_error=True`的参数，在该情形下插入操作将插入尽可能多的数据，并在最后一次插入失败后给出错误报告。

##### 查找特定页面的所有事件

可以为待查询的字段增加索引。

##### 旁白：管理索引大小

创建索引的大小会占用RAM。当随机访问一个索引时，在现在这个情形下是访问path索引，需要将所有的索引都驻留内存。

可以使用collstats数据库命令来查看索引的大小：

```
db.command('collstats', 'events')['indexSizes']
```

##### 查找特定事件的所有事件

查找某个特定时间段的事件的时候，索引将会优化性能，同时这种索引是一个右对齐索引，不会全部载入内存。

##### 查找特定主机/日期的所有事件

在同时查询两个条件（例子中是主机+时间范围）的时候，可以使用组合索引来优化性能，值得注意的是组合索引是有顺序的。

```
db.events.ensure_index([('time':1),('host':1)])
```
或
```
db.events.ensure_index([('host':1),('time':1)])
```

##### 索引设计规则

因为索引是使用B树存储的，那么下面的这些规则将有利于提高使用效率：

- 任何需要平等查询的字段都应该在索引定义的前面出现。
- 用于排序的字段应该在出现索引定义后。如果采用多个字段排序（例如last_name，first_name），那么应该和索引定义中出现的顺序相同。
- 采用区间查询的字段应该在索引定义的最后出现。

这会导致出现一些不幸的场景，在这些场景下索引无法最优化使用：

- 无论何时使用两个或者更多属性的范围查询，那么在索引中这多个属性就无法同时有效；
- 无论何时在使用区间查询时，如果合并使用了一个不同属性的排序，那么索引的效率会比相同属性集排序的方式效率低一些。

在上述情形下，最佳的方法是使用代表性的数据来测试，并多使用explain()方法。如果发现MongoDB查询优化器正在选择一种不好的索引方式（比如在进行巨大的内存里排序时，选择降低条目扫描的数量），也可以使用hint()方法高速如何选择索引。

##### 根据日期和页面来计算请求

处理一些聚合操作，比如`$sum`等操作，可以使用MongoDB2.1版本的聚合框架来选择、处理和聚合来自海量文档的结果，进而实现更强大的特定查询。（建议阅读原作参看示例代码P47）

等价的SQL类似于：含有where和group by的语句。

注意必须确保初始的$match查询有一个索引。

#### 分片需要考虑事项

##### 限制

在分片环境中，最大插入速率的限制是：

- 集群的分片数目。
- 选择的片键。

因为MongoDB使用基于片键范围的分块来分布数据，片键的选择可以控制MongoDB的数据分布，并影响系统写入和查询的性能。

理想情况下，片键应具备两个特性：

- 在各个分片之间平衡数据插入。
- 大多数查询可以路由到满足需要的分片的子集。

##### 选择1：根据时间分片

尽管使用时间戳，或者是使用_id字段的ObjectId，会将数据平均分布在各个分片上，这些片键会导致两个问题：

- 所有插入操作总是流向相同的分片，这就意味着分片集群拥有和单个实例相同的吞吐量。
- 假定频繁访问近期数据，那么大多数读操作倾向于读取集群中相同的分片。

##### 选择2：根据半随机键来分片

比如使用基于_id的hash值作为片键，可以分散写压力，但是存在如下缺点：

- 片键和片键的索引将消耗数据库的额外的存储空间。
- 查询，除非它们包含了片键本身，必须在所有分片上并行执行，这将导致性能的下降。

##### 选择3：根据数据集中平均分布的键来进行分片

如果文档中某个字段的值是在文档中平均分布的，那么强烈建议考虑使用该键来作为片键。这样做有很多的好处：

- 可以平均分布各个分片的写操作。
- 读操作可以是有选择的，如果查询选择指定path字段，那么可以定位到单个分片上。

潜在的缺陷是：所有命中一个特定的查询条件都必须指向同一个文件块，该块不能被MongoDB切分，因为在该块中的所有文档都有相同的片键。如果负载比较平均，则可能不是问题。但是如果负载不均匀，最终就会导致生成一个很大的文件块，该文件块不能被切分，并导致分片上的负载无法平衡。

##### 选择4：根据综合使用固有的和合成的键来进行分片

MongoDB支持采用组合片键，该组合键可以综合选择2和选择3的的最佳方面。

##### 测试自己的数据

选择片键十分困难的，因为没有决定性的“最佳实践”，分片的选择在很大程度上影响了性能，并且在选定片键后很难，或者几乎是不可能重新选择片键。

选择片键的最好的方法还是分析应用程序中真实的插入操作和查询操作。

#### 管理事件数据增长

MongoDB中的即使是数据已经从数据库中移除后，数据库文件在磁盘中的大小将永远不会缩小。

##### 有上限的集合

有上限的集合（capped collection）拥有一个固定的大小，在插入新数据达到上限时，会自动丢弃旧的数据。且当前版本中还不支持对有上限的集合进行分片。

##### TTL集合

如果希望既具备类似有上限的集合的功能，同时又可以分片，那么可以考虑使用在集合上使用“生存时间”（TTL）索引。如果在集合上定义了TTL索引，那么MongoDB使用remove()操作定期从集合中移除旧的文档。

相比有上限的集合，TTL索引不具备性能优势，它只是使用了remove方法，会导致数据碎片，并且在移除旧文档时仍然会触发索引查询。

##### 多集合，单数据库

定期重命名事件集合，以便数据集合可以像日志文件一样进行轮换。

##### 多数据库

循环使用数据库，而不是如之前的“多集合，单数据库”那样循环使用集合。

### 预聚合报告

#### 解决方案概述

支持分钟级、秒级的实时数据。

它实际上就是提前设计一个目标统计的模型，然后在记录日志的同时，更新该统计模型的值，以便在需要查询的时候，直接读取这个统计模型，而不是从原始数据中进行计算。

#### 模式设计

##### 每天每个页面单个文档，文本文档格式

优势：

- 对于网站上每个请求，只需要更新一个文档。
- 关于一天内针对单个网页的报告只需要访问单个文档。

同时，如果一些值是在填入数据的时候才赋值，那么在数据添加到该字段的时候，文档会变大，这可能导致MongoDB要重新分配这些文档，从而导致性能下降（大意是：动态分配空间）。可以使用提前分配的方式，先给预留数据，比如默认0，后续只需要update这个字段即可。

##### 每天每个页面一个文档，分层文档格式

一个较大的文档对象，如：

```
minutes:{
    "0": 3612,
    "1": 3241,
    ...
    "1439": 2819
}
```

访问0和访问1439的性能是不同的，因为在MongoDB的内部，它的表现实际上是一个键值对的数组，需要按序扫描来查找实际所需要更新的值的具体位置。

为了解决较大文档对象的问题，可以将这些值进行细分，比如该例子中，表示的是一天的分钟数，那么可以先拆解为24个小时，再将不同的分钟数放置到下面，从而提高性能：

```
minutes:{
    "0":{   "0": 3612,
            "1": 3241,
            ...
            "59": 2833
        }
    "1":{   "60": 3233,
            "61": 313,
            ...
            "119": 839
        }
    ...
    "23":{  
            ...
            "1439": 2819
        }
}
```

##### 根据粒度级别划分文档

以上的示例是针对网页的日统计，如果要增加月统计，可以依葫芦画瓢再加一个类似的，只不过这次是针对月级别的。

#### 操作

可以使用upsert=True来实现原地更新。

同时可以直接读取统计结果，用来展示。

#### 获取创建历史图表的数据

通过设定条件，并匹配索引，可以高效查询单个网页过去几个月内的查询。

#### 分片需要考虑事项

在这个示例中，可以按照site-page-date进行分片，以获得较好的扩展性。

### 分层聚合

使用MapReduce的方法从原始数据中分层计算数据结果集。以本章例子来看：

事件日志->小时级统计->天级统计->周级统计->月级统计->年级统计。

高级的输入可以由低级的输入来组成。

（因示例复杂，建议阅读原文）

第5章 电子商务
------------------

第6章 内容管理系统
------------------

第7章 在线广告网络
------------------

第8章 社交网络
------------------

第9章 在线游戏
------------------

后记
------------------