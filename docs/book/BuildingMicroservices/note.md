微服务设计（Building Microservices）
========================================

[英]Sam Newman著

崔力强 张骏 译

第1章 微服务
---------------------

微服务的诞生离不开下面这些技术实践的发展，而这些技术在10年前几乎是很难想象的：

| 实践类型      |    作用/现象                                            |
|:------------:|:-----------------------------------------------------:|
| 领域驱动设计   | 帮助理解用代码呈现真实世界的重要性、告诉我们如何更好建模        |
| 持续交付      | 如何更有效及高效地发布软件产品                              |
| 按需虚拟化     | 能够按需创建机器并调整其大小                               |
| 基础设施自动化  | 很容易从一台机器扩展到多台                                |
| 小型自治团队   | 对某个服务的全生命周期负责                                |
| 大型集群系统   | Netflix分享了构建大型反脆弱系统的经验                      |

### 1.1 什么是微服务

微服务就是一些协同工作的**小**而**自治**的服务。

#### 1.1.1 很小，专注于做好一件事

微服务的理念：单块系统->抽象层或模块->内聚性->确定服务边界。

在考虑微服务的时候，内聚性这一概念很重要。[单一职责原则](http://programmer.97things.oreilly.com/wiki/index.php/The_Single_Responsibility_Principle)认为：把因相同原因而变化的东西聚合到一起，而把不同原因而变化的东西分离出来。该论述很好地强调了内聚性这一概念。

微服务将这个理念应用在独立的服务上。根据业务的边界来确定服务的边界，这样就很容易确定某个功能代码应该放在哪里。

代码库多小才算小？作者的答案是：

1. **足够小即可，不要过小**。用户通常能够意识到“过大”，那么当他们不觉得“过大”的时候，就说明足够小了。

2. **和团队结构匹配**。

服务越小越好吗？不是。服务越小，独立性带来的好处就越多，但是管理大量服务也会越复杂。

#### 1.1.2 自治性

1. **相互隔离**：服务的部署应该尽量隔离，尽量避免在一台机器上。服务之间均通过网络调用进行通信，从而加强了服务之间的隔离性，避免紧耦合。

2. **低耦合**：你是否能够修改一个服务并对其进行部署，而不影响其他任何服务？

### 1.2 主要好处

#### 1.2.1 技术异构性

最合适的技术，最大生产力：在不同的服务中使用最适合该服务的技术，也将从这些最适合的技术中受益。

#### 1.2.2 弹性

因为分散，所以安全：在单块系统中，如果服务不可用，则所有的功能都会不可用。在微服务架构中，服务边界形成了舱壁，本身就能够很好地处理服务不可用和功能降级的问题。

#### 1.2.3 扩展

独立，所以可以分别扩展：可以对单个微服务进行扩展，而不是对整个单块应用进行扩展，因此使系统扩展变得更容易。

#### 1.2.4 简化部署

独立，所以可以单独部署：两次发布之间的差异越大，出错的可能性就越大。单块系统任何变更都需要全部发版。但微服务可以单独发版，如果失败也可以较容易回滚。

#### 1.2.5 与组织机构相匹配

小型代码库+小团队更高效：大团队和大代码库经常容易引起问题。微服务架构可以很好地将架构与组织结构相匹配，避免出现过大的代码库。从而获得理想的团队大小及生产力。

#### 1.2.6 可组合性

支持不同应用种类：在微服务的架构中，系统会开放很多接缝供外部使用。现在的应用程序种类繁多，包括Web、原生应用、移动端Web、平板应用、可穿戴设备等，针对每一种都应该考虑如何对已有功能进行组合来实现这些应用。

#### 1.2.7 对可替代性的优化

因为小，所以可以删了重写：如果是单块系统庞大而无人敢碰，同时对业务至关重要，维护起来：工作量很大、风险很高。微服务架构，服务小，重写或移除一个或者多个服务的阻碍也很小。

### 1.3 面向服务的架构

实施SOA会遇到这些问题：

1. 通信协议（如SOAP）如何选择

2. 第三方中间件如何选择

3. 服务粒度如何确定

现有的SOA知识并不能帮助你把应用程序划小。它没有提到多大算大，也没有讨论如何在现实世界中有效地防止服务之间的过度耦合。由于这些点没有说清楚，所以你在实施SOA时会遇到很多问题。

在现实世界中，由于我们对项目的系统和架构有着更好的理解，所以能够更好地实施SOA，而这事实上就是微服务架构。可以认为微服务架构是SOA的一种特定方法。

### 1.4 其他分解技术

#### 1.4.1 共享库

缺点：

1. 无法选择异构技术

2. 会失去独立地对系统某一部分进行扩展的能力。

3. 每次更新都需要重新部署整个进程。

4. 缺乏一个明显的接缝来建立架构的安全性保护措施，从而无法确保系统的弹性。

#### 1.4.2 模块

缺点：

1. 有些语言不支持模块，则模块作者需要做更多工作来对模块进行适当的隔离，比如Java的OSGI。

2. 一个进程内，模块之间的耦合性难以控制。

3. 模块受限于语言，技术异构性受限。

### 1.5 没有银弹

使用微服务架构，必须要面对所有分布式系统需要面对的复杂性。

为了得到微服务的好处，需要：

1. 在部署、测试和监控等方面做很多的工作。

2. 考虑如何扩展系统。

3. 保证它们的弹性。

4. 处理类似分布式事务或者与CAP相关的问题。

### 1.6 小结

本章介绍了微服务、微服务与其它组合技术有何不同，以及它能够带来的主要好处是什么。

第2章 演化式架构师
---------------------

### 2.1 不准确的比较

架构师的一个重要职责是，确保团队有共同的技术愿景，以帮助我们向客户交付他们想要的系统。

架构师会经常被与建筑师进行对比。但事实上，架构师要创造的东西从设计上来说就是要足够灵活，有很好的适应性，并且能够根据用户的需求进行演化。

### 2.2 架构师的演化视角

| 特征                | 建筑师          | 城市规划师 | 软件架构师 |
|:-------------------:|:--------------:|:--------:|:---------:|
|需求变更              | 少量            | －      |   大量    |
|某个时间点后不再变化    | 是              | －       |   否     |
|把握大方向            | 更多关注于细节    | 是       |   是     |

结论：软件架构师应该像城市规划师一样，专注在大方向上，只在很有限的情况下参与到非常具体的细节实现中来。他们需要保证系统不但能够满足当前的需求，还能够应对将来的变化。而且他们还应该保证在这个系统上工作的开发人员要和使用这个系统的用户一样开心。

### 2.3 分区

架构师应该多关注区域（服务）之间的交互，而不需要过于关注各个分区（服务）内部发生的事情。

### 2.4 一个原则性的方法

#### 2.4.1 战略目标

软件架构师不用制定战略目标（那是公司高层的事儿），但是需要确保在技术层面的选择能够与之一致。

所以需要花费更多的时间和组织内非技术的部分（业务部门）进行交互。

#### 2.4.2 原则

根据战略目标制定一些具体的规则，称为原则，它不是一成不变的。

> Heroku的12 Factors（[https://12factor.net/zh_cn/](https://12factor.net/zh_cn/)）就是一组这样的设计原则。

#### 2.4.3 实践

通过相应的实践来保证原则能够得到实施，这些实践能够指导我们如何完成任务。

#### 2.4.4 将原则和实践相结合

要有一些重要的原则来指导系统的演化，同时也要有一些细节来指导如何实现这些原则。

在一些大型组织中，可能.NET团队有一套原则，Java团队有另一套原则，但背后的原则是相同的。

#### 2.4.5 真实世界的例子

真实世界中，实践改动可能很频繁，原则基本上不怎么变。

要确保这些实践和原则的贯彻落实，可以用：文档、示例、甚至可以创造一些工具来保证。

### 2.5 要求的标准

如何识别出各个服务需要遵守的通用规则：

#### 2.5.1 监控

确保所有的服务使用同样的方式报告健康状态及其与监控相关的数据。不要为了服务的具体实践而改变监控系统。

#### 2.5.2 接口

选用少数几种明确的接口技术有助于新消费者的集成。这不仅是指技术和协议（如：HTTP/REST），也包括了URL是动词还是名词，如何处理资源分页，如何处理不同版本的API？

#### 2.5.3 架构安全性

必须保证每个服务都可以应对下游服务的错误请求，才能保证系统的健壮性。

### 2.6 代码治理

用简单的方式把事情做对：

#### 2.6.1 范例

如果在系统中人们有比较好的代码范例可以模仿，那么他们也就不会错得很离谱。而且这些范例最好来自真实的代码，而不是专门实现的完美的例子。

#### 2.6.2 裁剪服务代码模板

当开发人员想要实现一个新服务时，所有实现核心属性的那些代码都应该是现成的。这些裁剪的服务代码模板不应该是某个中心化组织、团队或工作的职责，最好是通过合作的方式进行定义，使用内部开源的方式能够很好地完成这项工作。

### 2.7 技术债务

走捷径可能会引入技术债务。有时候系统的目标会发生改变，并且与现有的实现不符，这种情况下也会产生技术债务。

架构师的职责就是从更高的层次出发，理解如何做权衡。

### 2.8 例外管理

如果一个例外出现的次数多了，可能就需要修改原则来将这些理解固化下来。

微服务团队通常有更好的自治性，因此也有更好的自由度。

### 2.9 集中治理和领导

架构师的一个职责就是确保有一个技术愿景，那么治理就是要确保我们构建的系统符合这个愿景，而且在需要的时候还应对愿景进行演化。

一种有效的模式是，组建一个小组，由架构师来领导，每个交付团队都有人参加，并且保证有来自高层的支持。

### 2.10 建设团队

执行愿景不仅仅等同于做技术决定，更重要的事情，是帮助你的队友成长，帮助他们理解这个愿景，并保证他们可以积极地参与到愿景的实现和调整中来。

伟大的软件来自于伟大的人，如果你只担心技术问题，那么恐怕你看到的问题远远不及一半。

### 2.11 小结

演进式架构师应该承担的职责：愿景、同理心、合作、适应性、自治性、治理，应该理解，成功要靠不断地取舍来实现。

第3章 如何建模服务
---------------------

### 3.1 MusicCorp简介

作者打算用一个虚构的例子来解释微服务。

### 3.2 什么样的服务是好服务

#### 3.2.1 松耦合

修改一个服务，就不需要修改另一个服务。

#### 3.2.2 高内聚

如果要改变某个行为，最好只能在一个地方修改，然后可以尽快发布。

### 3.3 限界上下文

《领域驱动设计》的作者Eric说：“细胞之所以会存在，是因为细胞膜定义了什么在细胞内，什么在细胞外，并且确定了什么物质可以通过细胞膜”。

#### 3.3.1 共享的隐藏模型

不同的限界上下文中，使用相同的模型进行通信。应该共享特定的模型，而不应该共享内部表示，可以避免潜在的紧耦合风险。

#### 3.3.2 模块和服务

单块系统中也要使用模块的概念进行划分，这些模块的边界就可以成为绝佳的微服务候选。

#### 3.3.3 过早划分

过早将一个系统划分成为微服务的代价非常高，尤其是在面对新领域时。很多时候，将一个已有的代码库划分成微服务，要比从头开始构建微服务简单得多。

### 3.4 业务功能

考虑组织内的限界上下文时，不应该从共享数据的角度来考虑，而应该从这些上下文能够提供的功能来考虑。避免出现贫血模型（仅包含CRUD的服务）。

首先要问自己“这个上下文是做什么用的”，然后再考虑“它需要什么样的数据”。

### 3.5 逐步划分上下文

从一开始识别出粗粒度的限界上下文，到这些限界上下文内部又出现了嵌套限界上下文。

有两种规则用来与外部协作：

1. 使用高层次的限界上下文，并将请求在内部映射给内部的嵌套上下文。

2. 高层次的限界上下文不应该被显式地建模成一个服务，而是直接将内部的嵌套上下文直接暴露出来。

使用哪种规则应该根据：

1. 组织结构

2. 代码的维护团队（如果是一个团队管理，则倾向于用第一种）

3. 如何更好地测试

等多个方面综合考虑。

### 3.6 关于业务概念的沟通

微服务之间如何就同一个业务概念进行通信，也是一件很重要的事情。基于业务领域的软件建模不应该止于限界上下文的概念。在组织内部共享的那些相同的术语和想法，也应该被反映到服务的接口上。以跟组织内通信相同的方式，来思考微服务之间的通信形式是非常有用的。

### 3.7 技术边界

服务边界通常不应该是技术接缝（按不同的技术，划分不同的服务），虽然这并不总是错的。

作者举例，某公司将前端和后端分拆成两个部分，形成两个服务，最后导致前后端每次都需要同时修改。

### 3.8 小结

什么是好服务，使用限界上下文寻找高内聚低耦合的接缝，通过将微服务与这些边界相匹配，保证最终的系统能够得到微服务提供的所有好处。

第4章 集成
---------------------

### 4.1 寻找理想的集成技术

#### 4.1.1 避免破坏性

尽量避免一个服务的修改会导致另一个服务的修改。

#### 4.1.2 保证API的技术无关性

技术日新月异，只有保持技术无关性才能更灵活。

#### 4.1.3 使你的服务易于消费方使用

好用的服务，才有意义。

增加一个客户端库可以简化消费方的使用，但是会造成耦合度增加。

#### 4.1.4 隐藏内部实现细节

避免使用倾向于暴露内部细节的技术。

### 4.2 为用户创建接口

此处“为用户创建接口”的标题是指为示例MusicCrop创建一个用户的例子。

接口通常不是一个简单的CRUD操作，而是一组相关性很强的业务集合，比如创建用户的例子：添加新客户可能会触发一个新流程，比如进行付账设置、发送欢迎邮件等。

### 4.3 共享数据库

**优点：**

- 简单、集成快

**缺点：**

使得高内聚和低耦合两者都难以实现

- 暴露内部细节，增加耦合性，使得变更表结构等变得困难重重；

- 数据库技术导致了对共享者的技术绑定，使得更换数据库变得困难重重；

- 使得程序逻辑也需要被共享者知道。

### 4.4 同步与异步

**同步：**

- 请求/响应：客户端发起一个请求，然后等待响应

**异步：**

特点：对运行时间较长的任务比较有用

- 请求/响应：客户端发起一个请求，然后注册一个回调，当服务操作结束之后，会调用该回调。

- 事件：客户端发布一个事件，然后期待协作者接收到该消息，并且知道该怎么做。因此可以在不影响客户端的情况下添加订阅者。

如何选择同步还是异步：

一个重要的因素是这种风格能否很好地解决复杂问题，比如如何处理跨服务边界的流程，而且这种流程有可能会运行很长时间。

### 4.5 编排与协同

**编排：**

就像管弦乐队的指挥，按照流程图的设计，执行每一步任务，如果是同步的请求/响应模式，甚至可以知道每一步是否成功。

缺点：

- 作为中心控制点承担了太多的职责。

- 大多数重量级编排方案都非常不稳定而且代价很大。

**协同：**

通过发布事件和订阅事件来消除耦合。

缺点：

- 看不到明显的业务流程图。

- 需要做一些额外的监控以确保正确性。

### 4.6 远程过程调用

#### 4.6.1 技术的耦合

类似Java RMI与特定的平台紧密绑定，对于服务端和客户端的技术选型造成了一定限制。而Thrift和protocol buffers对于不同的语言的支持很好。

#### 4.6.2 本地调用和远程调用并不相同

即便很多RPC的实现隐藏了远程调用的复杂性，但它们仍然不一样。

网络并不可靠，它随时有可能出错。

#### 4.6.3 脆弱性

那些能自动生成代码桩的技术，如Java RMI，任何修改都需要重新生成桩。导致了客户端和服务端的部署无法分离。

#### 4.6.4 RPC很糟糕吗

其实也不是。

不要对远程调用过度抽象，以至于网络因素完全被隐藏起来；

确保你可以独立地升级服务端的接口而不用强迫客户端升级；

在客户端中一定不要隐藏我们是在做网络调用这个事实；

在RPC的方式中经常会在客户端使用库，但是这些库如果在结构上组织得不够好，也可能会带来一些问题。

### 4.7 REST

REST是RPC的一种替代方案。

最重要的一点概念是：资源。

REST的风格可以参考：[Richardson的成熟度模型](http://martinfowler.com/articles/richardsonMaturityModel.html)

#### 4.7.1 REST和HTTP

REST并不限定是HTTP，但通常是HTTP。它们的定义都是针对资源的操作。

基于HTTP就可以利用到很多HTTP生态系统里的支撑工具和技术，比如缓存、代理、负载均衡、监控工具。

同样是基于HTTP，SOAP就用到了HTTP较少的特性，从而仅被当作传输协议来做RPC。

#### 4.7.2 超媒体作为程序状态的引擎

REST引入的用来避免客户端和服务端之间产生耦合的另一个原则是：HATEOAS（[Hypermedia As The Engine Of Application State](https://en.wikipedia.org/wiki/HATEOAS)）。

作者举了一个形象的例子：人类和网页这个超媒体之间是如何交互的。考虑Amazon.com这个站点。随着时间的推移，购物车的位置、图像、链接都有可能发生变化，但是人类足够聪明，你还是能够找到它。无论确切的形式和底层使用的控件发生怎样的改变，我们仍然很清楚如果你想要浏览购物车的话，应该去点哪个按钮。这就是为什么在网页上可以做出一些增量的修改，只要这些客户和站点之间的隐式约定仍然满足，这些修改就不会破坏站点的功能。

使用超媒体控制时，我们希望电子用户（服务）也能达到同样的聪明程度。可以用类似下面的表示：

```
<album>
  <name>Give Blood</name>
  <link rel="/artist" href="/artist/theBrakes" />
  <description>Aweson, short, brutish, funny and loud. Must buy!</description>
  <link rel="/instantpurchase" href="/instantpurchase/1234" />
</album>
```

其中`rel`很好地屏蔽了`href`。这样我们就可以随意改变链接的展现形式。

缺点：

客户端和服务端之间的通信次数会比较多，因为客户端需要不断地发现链接、请求、再发现链接，直到找到自己想要进行的那个操作，所以终究还是需要做一些取舍。

#### 4.7.3 JSON、XML还是其他

JSON轻量，XML全面。

JSON的缺点：XML使用链接来进行超媒体控制，而JSON标准中并没有类似的东西，所以出现了很多不同的自定义的方式在JSON中进行超媒体控制。[HAL](http://stateless.co/hal_specification.html)就是其中一种，

#### 4.7.4 留心过多的约定

有一些工具会为了短期利益而牺牲长期利益，为了让你一开始启动地足够快，它们会使用一些不好的实践。比如有些框架很容易表示数据库对象，并把它们反序列化成进程内的对象，然后直接暴露给外部。这种方式内在的耦合性所带来的痛苦会远远大于从一开始就消除概念之间的耦合所需要的代价。

避免它：先设计外部接口，再实现内部持久化。

#### 4.7.5 基于HTTP的REST的缺点

易用性角度看：

基于HTTP的REST无法自动生成客户端桩代码，而RPC可以。

在客户端和服务端共享代码是非常危险的。

有些WEB框架无法很好地支持所有的HTTP动词，也就可能无法完整地使用REST风格了。

性能：

每个HTTP请求的封装开销可能是个问题。JSON和Thrift等这样的二进制协议也是无法比的。和WebSocket等TCP传输协议也比不了。因此它对低延迟的场景并不是最优选项。

即便这些缺点，在选择服务之间的交互方式时，基于HTTP的REST仍然是一个比较合理的默认选择。

### 4.8 实现基于事件的异步协作方式

#### 4.8.1 技术选择

主要有两个部分需要考虑：微服务发布事件机制和消费者接收事件机制。

1. 使用消息队列：

  类似RabbitMQ这样的消息代理能够处理上述两个方面的问题。

  但是中间件服务厂商倾向于把很多软件打包进去，比如ESB。原则：尽量让中间件保持简单，而把业务逻辑放在自己的服务中。

2. 另一种方法是使用HTTP来传播事件。

  ATOM是一个符合REST规范的协议，可以通过它提供资源聚合（feed）的发布服务，而且有很多现成的客户端库可以用来消费该聚合。这样当客户服务发生改变时，只需简单地向该聚合发布一个事件即可。消费者会轮询该聚合以查看变化。另一方面，现成的ATOM规范和与之相关的库用起来非常方便，而且HTTP能够很好地处理伸缩性。

  但是有一种场景需要避免，即多个工作者处理了同一条消息，从而造成浪费。如果使用消息代理，一个标准的队列就可以很好地处理这种场景。而使用ATOM的话，就需要自己在所有的工作者之间维护一个共享的状态来减少上述情况发生。

#### 4.8.2 异构架构的复杂性

1. [灾难性故障转移（Catastrophic failover）](http://martinfowler.com/bliki/CatastrophicFailover.html)

  例如：代码存在bug会导致工作者崩溃。当工作者崩溃之后，这个请求上的锁会超时，然后该请求就会被放回到队列中。另一个工作者会重新尝试处理该请求，然后它也会崩溃。

  可以通过设置最大作业重试次数，以及消息医院（死信队列）来存放失败的消息。

2. 需要确保流程有很好的监控机制，并考虑使用关联ID，这种机制可以帮助你对跨进程的请求进行追踪。

### 4.9 服务即状态机

当消费者想要对客户做修改时，它会向客户服务发送一个合适的请求。客户服务根据自己的逻辑决定是否接受该请求。客户服务控制了所有与客户生命周期相关的事件。我们想要避免简单地对CRUD进行封装的贫血服务。如果出现了在客户服务之外与其进行相关的修改的情况，那么你就失去了内聚性。

### 4.10 响应式扩展

当你需要做一些基于多个服务调用的操作时，尝试一下适合你所选用技术栈的响应式扩展（[Reactive extensions，RX](https://msdn.microsoft.com/library/hh242985.aspx)）。

响应式扩展提供了一种机制，在此之上，你可以把多个调用的结果组装起来并在此基础上执行操作。

### 4.11 微服务世界中的DRY和代码重用的危险

DRY是指避免复制代码。

跨服务共用代码很可能会引入耦合。

作者的经验是：在微服务内部不要违反DRY，但在跨服务的情况下可以适当违反DRY。服务之间引入大量的耦合会比重复代码带来更糟糕的问题。

**客户端库**

建议客户端库不要引入服务无关的代码，它仅应该是处理一下底层API的封装（如SOAP或REST），可以处理服务发现、故障模式、日志等方面和服务本身职责无关的内容。

如果条件允许，客户端库可以交由非服务开发团队来完成，以降低耦合性出现的可能。

使用客户端库的好处，在于可以保证系统的可靠性和可伸缩性，保证客户端和服务器之间的通信能够在规模化的情况下正常工作。

### 4.12 按引用访问

按引用访问，可以避免在真正使用资源的时候，原有的资源已经失效了，所以可以将原始资源的引用（可能是URL）一并提供，这样在真正使用的时候，再进行查询。比如在系统间传递客户信息的时候仅传递客户ID，而在用到具体信息，如收货地址的时候，再向客户服务查询该客户的地址，避免因传输过长的时间，而客户地址已经发生了变化。在这样使用的时候，同样要避免耦合性的发生。有一些系统像是邮件系统，仅需要知道邮箱就可以了，而并不希望知道如何查询用户信息，再根据用户信息提取邮箱。

### 4.13 版本管理

#### 4.13.1 尽可能推迟

[容错性读取器](http://martinfowler.com/bliki/TolerantReader.html)：使用类似XPath这样的技术读取字段，以避免类似位置发生变化就导致客户端报错的问题。

[鲁棒性原则（Postel法则）](https://tools.ietf.org/html/rfc761)：对自己发送的东西要严格，对接收的东西要宽容。

#### 4.13.2 及早发现破坏性修改

建议使用消费者驱动的契约来及早定位这些问题。如果支持多种不同的客户端库，那么最好针对最新的服务对所有的客户端运行测试。一旦意识到，你可能会对某一个消费者造成破坏，那么可以选择要么尽量避免该破坏性修改，要么接受它，并跟维护这些服务的人员好好聊一聊。

#### 4.13.3 使用语义化的版本管理

语义化版本管理的每一个版本号都遵循这样的格式：MAJOR.MINOR.PATCH。

MAJOR：意味着其中包含向后不兼容的修改。

MINOR：意味着有新功能的增加。

PATCH：对已有功能的缺陷修复。

详见[这里](http://semver.org)

#### 4.13.4 不同的接口共存

在同一个服务上使用新接口和老接口同时存在。所以在发布一个破坏性修改时，可以部署一个同时包含新老接口的版本。一旦所有消费者不再访问老的接口，就可以删除掉该接口及相关的代码。

#### 4.13.5 同时使用多个版本的服务

短期内同时使用两个版本的服务是合理的，尤其当你做蓝绿部署或者金丝雀发布时。在这些情况下，不同版本的服务可能只会共存几分钟或者几个小时，而一般只会有两个版本。升级消费者到新版本的时间越长，就越应该考虑在同一个微服务中暴露两套API的做法。

### 4.14 用户界面

#### 4.14.1 走向数字化

很多公司倾向于把API设计地比较细粒度化，比如使用微服务架构所暴露出来的那些API。通过把服务的功能进行不同的组合，可以为桌面应用程序、移动端设备、可穿戴设备的客户提供不同的体验，如果客户来到实体店，甚至还可以通过这种组合提供更加真实的体验。

#### 4.14.2 约束

不同的交互形式存在着不同的约束，比如桌面Web应用和移动应用的约束是不一样的。

#### 4.14.3 API组合

API组合是指UI直接调用服务，在页面进行交互。

缺点：

1. 很难为不同的设备定制不同的响应。

2. 创建UI和服务是两个不同的团队的时候，即使很小的修改都需要多个团队的参与。

3. 与服务之间过多的交互对移动设备来说有些吃力。

#### 4.14.4 UI片段的组合

UI片段的组合是指让服务直接暴露出一部分UI，然后只需要把这些片段组合在一起就能创建整体。

缺点：

1. 用户体验的一致性。

2. 原生应用和胖客户端无法消费服务端提供的UI组件。

3. 有时候服务提供的能力难以嵌入到小部件或者页面中。

#### 4.14.5 为前端服务的后端

使用服务端的聚合接口或API入口对多个后端调用进行编排，并为不同的设备提供定制化的内容。

两种做法：（[http://samnewman.io/patterns/architectural/bff/](http://samnewman.io/patterns/architectural/bff/)）

1. 一个封装好的API负责编排后端的服务，并提供前端的移动应用、Web应用等的统一调用。

2. 与上一种做法略微不同的是，为移动应用、Web应用等，开发不同的移动后端和Web应用后端，再在这些后端上，组合不同服务的能力。（作者倾向于这一种）

#### 4.14.6 一种混合方式

以上各种模式各有特点，关键是要保持底层服务能力的内聚性。避免这些逻辑在系统中到处散布。

### 4.15 与第三方软件集成

与第三方软件集成可能会遇到下面的问题：

#### 4.15.1 缺乏控制

一切都只能依赖于厂商。

#### 4.15.2 定制化

那些标称能深度定制的产品经常会比改变组织使用的方式更难。

#### 4.15.3 意大利面式的集成

产品间集成协议互不相同带来的复杂性，或者允许直接访问内部数据所带来的耦合性问题。

#### 4.15.4 在自己可控的平台进行定制化

核心思想：任何定制化都只在自己可控的平台上进行，并限制工具的消费者的数量。

比如：在CMS系统前面套一层自己的代码，并把CMS当作一个内容管理平台来使用，而自己的代码控制经常需要变化的UI部分。

#### 4.15.5 绞杀者模式

[http://martinfowler.com/bliki/StranglerApplication.html](http://martinfowler.com/bliki/StranglerApplication.html)

当你使用遗留系统和COTS平台时，你通常无法完全控制他们，你需要考虑如果需要移除或绕过它们的话，应该如何操作。

绞杀者可以捕获并拦截对老系统的调用。这里你就可以决定，是把这些调用路由到现存的遗留代码中还是导向新写的代码中。这种方式可以帮助我们逐步对老系统进行替换，从而避免影响过大的重写。

### 4.16 小结

如何保证微服务之间的低耦合：

- 无论如何避免数据库集成。

- 理解REST和RPC之间的取舍，但总是使用REST作为请求/响应模式的起点。

- 相比编排，优先选择协同。

- 避免破坏性修改、理解Postel法则、使用容错性读取器。

- 将用户界面视为一个组合层。

第5章 分解单块系统
---------------------

### 5.1 关键是接缝

限界上下文就是一个非常好的接缝，因为它的定义就是组织内高内聚和低耦合的边界。所以第一步是识别出代码中的边界。

### 5.2 分解MusicCorp

识别出不同的上下文，并把已有的代码移动到相应的位置。一开始可能不需要完全把代码按照面向领域的方式组织起来。事实上把精力集中在一个地方通常更有价值。

### 5.3 分解单块系统的原因

慢慢开凿这些系统，最好先考虑一下把哪部分代码抽取出去得到的收益最大。

通过改变速度、团队结构、安全、技术等方面考虑，来评估这些收益。

### 5.4 杂乱的依赖

我们想要拉取出来的接缝应该尽量少地被其它组件所依赖。

### 5.5 数据库

不要用数据库作为服务之间的集成方式。如果这么做，意味着需要找到数据库中的接缝。

### 5.6 找到问题的关键

切断这些不同限界上下文之间底层数据库访问层的联系，单独为不同的上下文编写映射文件。同时还需要切断数据库中外键之间的约束。

### 5.7 例子：打破外键关系

当一个系统中存在外键的时候，将部分数据移植到服务中，如果还需要保持外键关系的话，则需要进行数据库集成，因此不可避免需要将原有的查询方式，调整为接口调用的方式。

可能带来的问题：

性能：你到底要有多快，或者说多慢你还能接受，如果这样的变动还在你可以接受的范围，则这样的改动，就是可以被允许的。

一致性：可以是增加额外的检查和校验，另外，一致性的问题从数据库移到了外面来实现，比如代码中，但有时候也可以从业务的角度来评估，比如真的是某个外键值没了，是否可以继续正确的业务呢？

### 5.8 例子：共享静态数据

类似国家代码这种变化极小的，甚至可以在代码中、配置文件中写，而没有必要放入数据库中（如果要分拆成多个服务，而不同的服务依赖不同的数据库，同时又需要这么一张表）。在多个数据库中，自己同步这些数据，也会引入潜在的一致性问题。

### 5.9 例子：共享数据

在一些场景下，看似多个业务都在更新同一张表，其实只是将业务建模的工作在数据库中，隐式完成了。如果在这种场景下要进行微服务拆分是很困难的。这时候就应该不断剥离业务实体，让这些概念具象化，然后最终才能得到一个清晰的服务。

### 5.10 例子：共享表

当使用共享表的时候，事实上是将关注点放在了一起，可以将这些表拆开来。

### 5.11 重构数据库

优先分离数据库而不是服务，好处在于可以随时选择回退这些修改或是继续做，而不影响任何消费者。

### 5.12 事务边界

分离服务后的结果就是导致原本拥有的数据库事务特性可能就丢失了。

#### 5.12.1 再试一次

利用队列或者日志文件，在之后再对其进行触发。很多地方会把这种形式叫作最终一致性。

#### 5.12.2 终止整个操作

另一个选择是拒绝整个操作。再发起一个补偿事务来抵消之前的操作。但是如果需要同步的操作很多，补偿事务会非常难以理解，更不用说实现了。

#### 5.12.3 分布式事务

分布式事务依赖中央事务管理器，并假定投票和提交两步操作之间都没有什么问题，比如网络延迟和中断，中央事务管理器宕机等。这种方案非常复杂，而且对系统的扩展性也不是很好。如果非要使用这种方案，也不建议自己实现，而是采用现成的方案。

#### 5.12.4 应该怎么办呢

如果遇到的场景需要保持一致性，那么尽量避免把它们放在不同的地方，一定要尽量这样做。如果实在不行，那么要避免仅仅从纯技术（比如数据库事务）的角度考虑，而是显式地创建一个概念来表示这个事务。你可以把这个概念当作一个句柄或者钩子，在此之上，能够相对容易地进行类似补偿事务这样的操作，这也是在系统中监控这些复杂概念的一种方式。举个例子，你可以创建一个叫作“处理中的订单”的概念，围绕这个概念可以把所有与订单相关的端到端操作（及相应的异常）管理起来。

### 5.13 报表

将服务拆分之后就带来了报表如何生成的问题。

### 5.14 报表服务器

单块系统将数据存储在一个数据库中，报表系统通常从数据库副本中读取数据，而针对副本所能够做的优化也非常有限。另外有的时候系统本身并不一定适用关系型数据库，而是非关系型数据库。

### 5.15 通过服务调用来获取数据

通过API调用数据，对于数据量小的报表系统可行，对于大数据量的报表系统则不可行。对于某些暴露的服务来说可以适用一些缓存头，将数据缓存在代理服务器等中间环节以提高数据的获取速度，但是仍然无法解决第一次获取数据太慢的问题。还有一种方式是返回HTTP 202响应码表示请求已经接受了但是还没有处理。调用系统接下来轮询这个资源，直到得到一个HTTP 201 Created状态，这表示请求已经被满足了，然后发起调用的系统就可以获取这个数据。通过这种方式可以将大数据文件导出，而不需要HTTP之上的开销，只是简单地把一个CSV文件存储到共享的位置而已。

### 5.16 数据导出

将数据从一个数据库中导出并导入到报表数据库中，虽然因此产生了耦合，但是我们可以把它看作一个类似公共API的比较稳定的东西。这里其实是把集成的复杂度推到了表结构这个层次，然后依靠数据库的能力来确保这种方式是可行的。

### 5.17 事件数据导出

在客户端编写自己的事件订阅器把数据导出到报表数据库中，一旦有新的事件，数据就会被发送到中央报表系统中。但是这种方式的缺点是必须将所有需要的信息都以事件的形式广播出去，所以在数据量比较大时，不容易像数据导出方式那样直接在数据库级别进行扩展。

### 5.18 数据导出的备份

使用Netflix提供的开源组件将数据导出到Cassandra中。

### 5.19 走向实时

不一定是所有的报表都必须从同一个地方（数据源）出（报表）。

### 5.20 修改的代价

尽量小和增量的修改，并且能够理解做出哪些改变会造成哪些影响。

### 5.21 理解根本原因

我们希望系统的架构随着时间的推移增量地进行变化。减少创建新服务的代价，给人们能够自助提供虚拟机的服务，甚至提供一个可以使用的PaaS，这些措施能够大大简化系统环境的创建及在此之上的测试工作。

### 5.22 小结

在最开始就要养成及时寻找系统接缝的好习惯，从而减少分割服务的代价，这样才能够在未来遇到新需求时继续演化我们的系统。

第6章 部署
---------------------

### 6.1 持续集成简介

CI能够保证新提交的代码与已有代码进行集成，从而让所有人保持同步。CI服务器会检测到代码已提交并签出，然后花些时间来验证代码是否通过编译以及测试能否通过。

[Jez Humble](https://continuousdelivery.com)用来测试别人是否真正理解CI的三个问题可以帮助回答“你真的在做CI吗？”：

- 你是否每天签入代码到主线？

- 你是否有一组测试来验证修改？

- 当构建失败后，团队是否把修复CI当作第一优先级的事情来做？

### 6.2 把持续集成映射到微服务

- 把所有微服务放在同一个代码库中，并且只有一个CI构建。这种方法导致任何一行代码签入都会引起整体重新验证和构建，不仅浪费时间，而且也不知道哪些构建物应该被重新部署。

- 这种方法的变体是，一个代码库，多个CI，映射到代码库的不同部分。这种方法容易导致多个服务耦合在一起。

- 每个微服务有一个源代码库和CI构建。在这样的世界中，跨微服务做修改会更加困难，但是相比单块代码库和单块构建流程所带来的问题而言，这个更容易解决（比如使用命令行脚本）。每个与微服务相关的测试也应该和其本身的代码放在一起，这样就很容易知道对于某个服务来说应该运行哪些测试。

### 6.3 构建流水线和持续交付

构建流水线可以很好地跟踪软件构建进度：每完成一个阶段，就离终点更近一步。流水线也能够可视化本次构建物的软件质量。构建物会在整个构建的第一个环节生成，然后它会被用在整个流水线中。随着构建物通过不同的阶段，我们越来越能确定该软件能够在生产环境下正常工作。

CD基于上述这些概念，并在此之上有所发展。CD能够检查每次提交是否达到了部署到生产环境的要求，并持续地把这些信息反馈给我们，它会把每次提交当成候选发布版本来对待。

当一个团队刚开始启动一个新项目时，尤其是什么都没有的情况下，你可能会花很多时间来识别出服务的边界。所以在你识别出稳定的领域之前，可以把初始服务都放在一起。

### 6.4 平台特定的构建物

不同的技术栈生成了不同类型的构建物，同时不同的构建物对环境的依赖还不一样，比如有Python可能需要Ngnix才能运行。

而且不同的构建物对部署有不同的要求，这个过程可能会很复杂。自动化可以对不同构建物底层部署机制进行屏蔽。Chef、Puppt及Ansible都支持一些通用技术栈的构建物部署。

### 6.5 操作系统构建物

使用操作系统特定构建物可以避免多种技术栈下的构建物所带来的问题，在做部署时不需要考虑底层使用的是什么技术。只需要简单使用内置的工具就可以完成软件的安装。这些操作系统工具也可以进行软件的卸载及查询，甚至还可以把CI生成的构建物推送到软件包仓库中。

但是缺点是，刚开始编写构建脚本的过程可能会比较困难。

### 6.6 定制化镜像

每次都在虚拟机上安装各种软件依赖，如JVM等，将会耗费大量的时间，定制自己的虚拟机镜像将使这件事简单点。

但这个方法有一些缺点。首先，构建镜像会花费大量的时间。其次，产生的镜像可能会很大。

[Packer](https://www.packer.io)可以选择自己喜欢的工具来从同一套配置中生成不同平台的镜像。

#### 6.6.1 将镜像作为构建物

把服务本身也部署在镜像内。

#### 6.6.2 不可变服务器

通过把配置都存到版本控制中，我们可以自动化重建服务，甚至重建整个环境。但是如果部署完成后，有人登录到机器上修改了一些东西呢？这就会导致机器上的实际配置和源代码管理中的配置不再一致，这个问题叫做_配置漂移_。

为了避免这个问题，可以禁止对任何运行的服务器手动修改。甚至可以在镜像的创建过程中禁止SSH，以确保没有人能够登录到机器上做任何修改。

### 6.7 环境

测试和生产环境的不一致性可能会带来意想不到的测试结果。比如测试环境一台服务器，生产环境使用负载平衡。

但是不同的环境的用途可能是不同的，我们只能希望各个环境不断地靠近生产环境，这样就可以快速捕获到由环境差异导致的问题。

### 6.8 服务配置

应该最小化环境间配置的差异。比如仅连接数据库的用户名和密码不同。

对于不同的环境之间的配置差异。一种做法是为不同的环境创建不同的构建物，并把配置内建在构建物中。但这样违背了持续交付的概念，测试通过的是测试环境，但是上线的却是生产环境。而且构建这些构建物会比较耗时。其次需要在构建的时候知道存在哪些环境。

一个更好的方法是只创建一个构建物，并将配置单独管理。从形式上说，可以针对每个环境一个属性文件，或者是传入到安装过程中的一些参数。还有一个在应对大量微服务时比较流行的方法是，使用专用系统来提供配置。

### 6.9 服务与主机之间的映射

#### 6.9.1 单主机多服务

当团队划分为一个管理软件一个管理基础设施，那么管理基础设施的团队的工作量和主机的数量成正比。而且虚拟化本身也会占用一些额外的资源。

这样做的坏处：

- 监控会变得复杂，一个服务可能会占用其他服务的资源。

- 部署也会变得复杂，它们的依赖不同甚至可能互相冲突。同时也放弃了微服务的一个好处：独立部署不同的服务。

- 不利于团队的自治性，不同的团队维护的服务部署在一台主机上，谁负责主机的维护？

- 会限制构建物的选择，基于镜像的部署模型就不用考虑了，因为服务器不可变。

- 增加单个服务进行扩展的复杂性。

#### 6.9.2 应用程序容器

使用IIS或者Java Servlet容器进行部署的模式可用来简化管理。这样做的坏处：

- 不可避免地限制技术栈的选择

- 限制自动化和系统管理技术的选择

- 一些容器还会在集群间共享会话状态，它会影响服务的可伸缩性。

可以考虑一些自包含的微服务构建物（例如，轻量级的HTTP服务器），如.NET平台的Nancy以及Java平台的Jetty等。

#### 6.9.3 每个主机一个服务

这个做法简化了监控和错误恢复，使我们有可能采用不同的部署技术。从整体上降低了系统的复杂性。可以把它看作减小微服务复杂性的一个方法。

但是主机数量的增加可能是个问题。管理更多的服务器，运行更多不同的主机也会引入很多的隐式代价。

#### 6.9.4 平台即服务

当使用PaaS时，你工作的抽象层次要比在单个主机上工作时的高。

但是现在成熟度还不够，如果你的应用程序越不标准，就越难一起和PaaS一起工作。

[HeroKu](https://www.heroku.com/)是一个黄金级的PaaS平台。

### 6.10 自动化

自动化是避免工作量随着服务器数量线性增加的重要手段。

### 6.11 从物理机到虚拟机

#### 6.11.1 传统的虚拟化技术

虚拟机本身会占用系统资源，当分配的主机越多，虚拟机本身占用的资源也就越多。

#### 6.11.2 Vagrant

[Vagrant](https://www.vagrantup.com/)可以使用文本文件来定义一系列虚拟机，并可以将文本文件提交到代码库中，与团队其他成员共享。

优势是可以在开发机上模拟各种场景。缺点是会有很多额外的资源消耗。

#### 6.11.3 Linux容器

Linux容器可以创建一个隔离的进程空间，进而在这个空间中运行其他的进程。

Linux的容器技术有很多，比如Solaris Zones和OpenVZ，但最流行的还是LXC。

它与传统虚拟机相比，首先不需要hypervisor，其次在其上运行的主机必须共享相同的内核。

容器的好处有：启动快（只需几秒），数量多（可以同时运行很多）。

容器也有问题：将内部网络暴露到外部可能会比较麻烦，而且容器不是完全隔离的，有许多文档和已知的方法介绍了容器中的进程可能会跳出容器与其他的进程进行交互，有些是设计如此，有些是bug。

#### 6.11.4 Docker

Docker是构建在轻量级容器之上的平台。它帮你处理了大多数与容器管理相关的事情。

它的应用抽象非常有用。还可以缓解运行过多服务进行本地开发和测试的问题。Kubernetes和CoreOS集群技术都可以帮助你跨多台机器管理Docker实例上的服务。

### 6.12 一个部署接口

不管用于部署的底层平台和构建物是什么，使用统一接口来部署给定的服务都是一个很关键的实践。

可以使用CI工具来触发脚本的调用，或者手动键入。从Windows批处理到bash，再到Python Fabric脚本等，所有这些命令行脚本的格式都大同小异。

[Terraform](https://www.terraform.io/)可以用来很好管理部署的复杂性。

### 6.13 小结

保持服务能够独立于其他服务进行部署的能力。

坚持每个服务一个代码库，每个服务一个CI，因为只有这样才能实现独立部署。

把每个服务放到单独的主机／容器中。看看类似LXC或者Docker这样的技术如何简化对多个服务的管理。

自动化的文化对一切管理来说都非常重要。

第7章 测试
---------------------

### 7.1 测试类型

尽可能多地使用自动化是近年来业界的一种趋势。如果当前你正在使用大量的手工测试，我建议在深入微服务的道路之前，先解决这个问题，否则很难获得微服务架构带来的好处，因为你无法快速有效地验证软件。

### 7.2 测试范围

自动化测试可以分为：单元测试、服务测试和用户界面测试（端到端测试）三层。

#### 7.2.1 单元测试

单元测试是面向技术而非面向业务的。单元测试对于代码重构非常重要，因为我们知道，如果不小心犯了错误，这些小范围的测试能很快做出提醒，这样我们就可以放心地随时调整代码。

#### 7.2.2 服务测试

服务测试是绕开用户界面、直接针对服务的测试。在独立应用程序中，服务测试可能只测试为用户界面提供服务的一些类。对于包含多个服务的系统，一个服务测试只测试其中一个单独服务的功能。

只测试一个单独的服务可以提高测试的隔离性，这样我们就可以更快地定位并解决问题。为了达到这种隔离性，我们需要给所有的外部合作者打桩，以便只把服务本身保留在测试范围内。

#### 7.2.3 端到端测试

通常需要打开一个浏览器来操作图形用户界面（GUI），也很容易模仿类似上传文件这样的用户交互。

#### 7.2.4 权衡

测试金字塔（从单元测试到服务测试到端到端测试，分别是从塔底到塔尖）的关键是，为不同的目的选择不同的测试来覆盖不同的范围。

越往塔尖，测试量越大，反馈周期越长，但是对系统的稳定性就越有信心。

#### 7.2.5 比例

一个好的经验法则是，顺着金字塔往下，下面一层的测试数量要比上面一层多一个数量级。

### 7.3 实现服务测试

#### 7.3.1 mock还是打桩

打桩和mock之间的区别很明显。Martin Flower把包括打桩和mock在内的所有这些术语统称为测试替身（Test Double，http://www.martinfowler.com/bliki/TestDouble.html)

#### 7.3.2 智能的打桩服务

可以使用类似[Mountebank](http://www.mbtest.org)的打桩/mock服务器，来避免自己创建打桩服务。

### 7.4 微妙的端到端测试

端到端测试通常需要部署多个服务，可以让多个流水线扇入（fan in）到一个独立的端到端测试的阶段（stage）。使用这种方法，任意一个服务的构建都会触发一次端到端测试。

### 7.5 端到端测试的缺点

端到端测试有很多缺点。

### 7.6 脆弱的测试

很多问题都会导致测试失败，但这些问题很多时候都和待测试的功能本身无关。

包含在测试中的服务数量越多，测试就会越脆弱，不确定性就越强。

要减少这种脆弱性，可能需要我们努力改进测试的方法，也可能需要改进我们被测的软件，使之更容易测试。

#### 7.6.1 谁来写这些测试

最好的平衡是共享端到端测试套件的代码权，但同时对测试套件联合负责。团队可以随意提交测试到这个套件，但实现服务的团队必须全部负责维护套件的健康。

#### 7.6.2 测试多长时间

测试可能会运行很长，可能的方法是采用并行测试。然而这种方法并不能代替去真正了解什么需要被测试，以及哪些不必要的测试可以删掉。

#### 7.6.3 大量的堆积

部署的变更内容越多，发布的风险就会越高，我们就越有可能破坏一些功能。保障频繁发布软件的关键是基于这样的一个想法：尽可能频繁地发布小范围的改变。

#### 7.6.4 元版本

如果将多个服务的修改使用了相同的版本，很快就会接受它们必须一起部署的事实，而这是危险的，它将导致失去微服务的一个主要优势，独立部署。

### 7.7 测试场景，而不是故事

把测试整个系统的重心放到少量核心场景上，而不是对所有的故事都添加端到端的测试。

### 7.8 拯救我们的消费者驱动的测试

在进行端到端测试之前引入CDC（Consumerr-Driven Contract，消费者驱动的契约）进行测试，服务本身的所有下游依赖都可以使用打桩。

#### 7.8.1 Pact

[Pact](https://github.com/realestate-com-au/pact)是一个消费者驱动的测试工具。

#### 7.8.2 关于沟通

CDC（Consumerr-Driven Contract，消费者驱动的契约），需要消费者和生产服务之间具有良好的沟通和信任。

如果你消费的服务由第三方提供，那么CDC可能不适用，因为你们可能缺乏充分的沟通和信任。在这种情况下，对可能出错的组件不得不使用有限的大范围的端到端测试。

换一个场景，如果是为成千上万的潜在的消费者创建API（比如一个公开可用的Web服务的API），你可能不得不自己扮演消费者（或者说一部分消费者）的角色来定义这些测试。破坏大量的外部消费者是非常糟糕的事情，这种情况下CDC就显得尤为重要！

### 7.9 还应该使用端到端测试吗

大多数人可能更喜欢使用CDC的工具和更好的监控来代替端到端测试。但这并不意味着端到端测试应该被全部扔掉。它们会在使用一种叫做语义监控的技术来监控生产系统时，用到端到端的场景测试。

可以把运行端到端测试当作把服务部署到生产环境的辅助。可以慢慢减少端到端的测试，直至完全不需要。

再怎么测试也不可能消除所有的缺陷，所以生产环境中有效的监控和修复还是有必要的。

### 7.10 部署后再测试

有些问题只有在部署生产之后才能发现。

#### 7.10.1 区分部署和上线

蓝绿发布：部署的时候会部署两份软件（新/旧），但只有一个接受真正的请求。在进行过各项测试后，再进行切换。可以通过DNS或者负载均衡来做。

#### 7.10.2 金丝雀发布

金丝雀发布是指通过将部分生产流量引流到新部署的系统，来验证系统是否按预期执行。

金丝雀发布和蓝绿发布的不同之处在于，新旧版本共存的时间更长，而且经常会调整流量。

#### 7.10.3 平均修复时间胜过平均故障间隔时间

尽快回滚加上良好的监控，让我们更能够在生产环境进行测试，同时承认上线的版本可能存在缺陷。

### 7.11 跨功能的测试

有些功能是由多个功能共同完成的，称为跨功能测试（CFR）。作者建议尽早去看CFR，并定期审查。

**性能测试**

随着系统被拆解成更多的微服务，跨网络边界调用的次数明显增加了。

性能测试要尽早开始，而不能拖到上线之前。性能测试也可以是各种范围测试的混合。

性能测试完成后一定要看结果，对性能应该确定目标，并对不符合目标的性能及时调优。

### 7.12 小结

- 优化快速反馈，并相应地使用不同类型的测试。

- 尽可能使用消费者驱动的契约测试，来替换端到端测试。

- 使用消费者驱动的契约测试，提供团队之间的对话要点。

- 尝试理解投入更多的努力测试与更快地在生产环境发现问题之间的权衡（MTBF与MTTR权衡的优化）。

第8章 监控
---------------------

微服务架构带来好处的同时也给监控带来了复杂性，要做好微服务下的监控，就要：监控小的服务，然后聚合起来看整体。

### 8.1 单一服务，单一服务器

- 监控主机，如使用Nagios和New Relic

- 监控服务器日志

- 监控应用（至少监控服务的响应时间）

### 8.2 单一服务，多个服务器

- 监控主机，既包括所有主机也包括单台主机

- 监控服务器日志

- 监控应用，可以在负载均衡器中完成

### 8.3 多个服务，多个服务器

从日志到应用程序指标，集中收集和聚合尽可能多的数据到我们的手上。

### 8.4 日志，日志，更多的日志

使用类似[logstash](http://logstash.net)，解析多种日志文件格式，并将它们发送给下游系统进一步调查。

[Kibana](https://www.elastic.co/products/kibana)是一个基于ElasticSearch查看日志的系统。

### 8.5 多个服务的指标跟踪

[Graphite](http://graphiteapp.org)，提供了一个非常简单的API，允许你实时发送指标数据给它。然后你可以通过查看这些指标生成的图表和其他展示方式来了解当前的情况。

### 8.6 服务指标

建议服务设计的时候就要公开自己的基本指标。比如服务被调用的次数等。

[Codahale的Metrics库](http://metrics.dropwizard.io/)可以帮助服务发送指标到一个标准系统中。

### 8.7 综合监控

除了对一些CPU等进行监控之外，还需要对真实的业务进行监控。

使用自动化测试的内容来对生产系统进行测试，可以有效地模拟真实的操作。

同样，我们还需要确保不会触发意料之外的副作用，比如在生产系统上测试下单并产生了真实的交易。

### 8.8 关联标识

服务大多由一系列服务组合调用而成，而这些服务之间的关系，可以用关联标识来跟踪。在触发第一个调用时，生成一个GUID。然后把它传递给所有的后续调用。

[Zipkin](https://github.com/openzipkin/zipkin)可以跨多个系统边界跟踪调用。它是基于Google的[Dapper论文](http://research.google.com/pubs/pub36356.html)而设计的。

### 8.9 级联

监控系统之间的集成点非常关键。每个服务的实例都应该追踪和显示其下游服务的健康状态，从数据库到其他合作服务。你也应该将这些信息汇总，以得到一个整合的画面。你会想了解下游服务调用的响应时间，并检测是否有错误。

### 8.10 标准化

应该尝试以标准格式的方式记录日志。可能需要为度量提供一个标准名称的列表；如果一个服务指标叫作ResponseTime，另一个叫作RspTimeSecs，而它们的意思是一样的，这会非常令人讨厌。

### 8.11 考虑受众

为不同的人收集不同的数据。需要考虑以下因素：

- 他们现在需要知道什么

- 他们之后想要什么

- 他们如何消费数据

### 8.12 未来

[Riemann](http://riemann.io/)是一个事件服务器，允许高级的聚合和事件路由。

[Suro](https://github.com/Netflix/suro)是数据流水线，解决和Riemann类似的问题。它可以明确处理两种数据，用户行为的相关指标和更多的运营数据（如应用程序日志）。

### 8.13 小结

对每个服务而言：

- 最低限度要跟踪请求响应时间。

- 最低限度要跟踪所有下游服务的健康状态。

- 标准化如何收集指标以及存储指标。

- 以标准的格式将日志记录到一个标准的位置。

- 监控底层操作系统。

对系统而言：

- 聚合CPU之类的主机层级的指标及应用程序级指标。

- 确保你选用的指标存储工具可以在系统和服务级别做聚合，同时也允许你查看单台主机的情况。

- 确保指标存储工具允许你维护数据足够长的时间，以了解你的系统的趋势。

- 使用单个可查询工具来对日志进行聚合和存储。

- 强烈考虑标准化关联标识的使用。

- 了解什么样的情况需要行动，并根据这些信息构造相应的警报和仪表盘。

- 调查对各种指标聚合方式做统一化的可能性，像Suro或Riemann这样的工具可能会对你有用。

第9章 安全
---------------------

### 9.1 身份验证和授权

#### 9.1.1 常见的单点登录实现

SAML和OpenID Connect是常见的标准。SAML比较复杂，但OpenID Connect则相对简单，是未来的趋势。

在公共服务中，类似Google可以作为OpenID的公共提供者，但是在企业内部，目前缺乏足够好的OpenID的身份提供者。

#### 9.1.2 单点登录网关

在微服务系统中，每个服务可以自己处理如何重定向到身份提供者，并与其进行握手。显然，这意味着大量的重复工作。使用共享库可以解决这个问题，但我们必须小心地避免可以能来自共享代码的耦合。而且如果有多个不同的技术栈，共享库也很难提供帮助。

可以考虑使用单点登录网关来集中处理重定向用户的行为。但这可能会遇到几个问题：

- 需要解决下游服务如何接收主体信息的问题。

- 孤立地在微服务中定位问题就变得更难。

- 会带来一种虚假的安全感。

#### 9.1.3 细粒度的授权

我们构建的软件要与组织的工作方式相匹配。所以也需要以这种方式来使用角色。

### 9.2 服务间的身份验证和授权

#### 9.2.1 在边界内允许一切

很多组织默认在网络范围内一切安全，但事实上这是不可靠的，而且很多时候一开始并没有意识到它的风险。

#### 9.2.2 HTTP(S)基本身份验证

使用HTTPS可以避免通信被监听，但是它可能有几个坏处：

- 如果使用的自签发证书，则会引入大量的复杂性

- 使用HTTPS会使反向代理无法缓存相关信息

#### 9.2.3 使用SAML或OpenID Connect

为客户端创建帐户，有时被称为服务帐户。然后通过现成的基础设施（SAML或OpenID Connect）来完成验证。

#### 9.2.4 客户端证书

使用TLS，在每个客户端都安装X.509证书，用于客户端和服务器端之间建立通信链路。

但是使用这种方法，证书管理的工作要比只使用服务器端证书更加繁重。因此，你应该在通过互联网发送非常重要数时才使用安全通信。

#### 9.2.5 HTTP之上的HMAC

这种方法有三个缺点：

- 如何共享密钥，要么两边都硬编码，要么通过某种协议共享，那么就得保证这个协议足够安全。

- 这是一种模式，但不是一个标准，因此缺乏一个优秀的、开放的且有效的实现方式。亚马逊的S3 API接口规范、[JWT](https://tools.ietf.org/html/rfc7519)都值得一看。

- 只能保证不被篡改，不能保证不被监听。

#### 9.2.6 API密钥

API密钥受欢迎的原因一部分源于：API密钥重点关注的是对程序来说的易用性。

它允许服务识别出是谁在进行调用，然后对他们能做的进行限制。限制通常不仅限于特定资源的访问，还可以扩展到类似于针对特定的调用者限速，以保护其他人服务调用的质量等。

#### 9.2.7 代理问题

有一种安全漏洞叫“混淆代理人问题”，指的是在服务间通信的上下文中，攻击者采用一些措施欺骗代理服务，让它调用其下游服务，从而做到一些他不应该能做的事情。

两种作法可以避免：

- 直接将原始的用户请求凭证传递给服务。但这样做将在每个服务上都实现验证。

- 调用服务的时候，不仅说明是调用什么，还需要告诉服务以谁的名义来调用。

### 9.3 静态数据的安全

#### 9.3.1 使用众所周知的加密算法

避免自己实现加密算法，尽量使用现成的加密算法。

关于密码，应该考虑使用一种叫做[加盐密码哈希](https://crackstation.net/hashing-security.htm#properhashing)。

#### 9.3.2 一切皆与密钥相关

密钥本身的存储很重要，比如不应该存储在加密数据相同的数据库中，这将给安全造成风险。

可以考虑使用单独的安全设备来加密和解密数据。也可以使用单独的密码库。

#### 9.3.3 选择你的目标

如果不打算对所有数据都加密，就要选择哪些数据应该被加密，比如需要放入日志文件中以帮助分析问题。

还需要考虑一些重构、数据库迁移等复杂度。

#### 9.3.4 按需解密

第一次看到数据的时候就对它进行加密。只有在需要时进行解密，并确保解密后的数据不会存储在任何地方。

#### 9.3.5 加密备份

备份本身也应该被加密。

### 9.4 深度防御

#### 9.4.1 防火墙

使用多个不同的防火墙来处理不同的防御内容。

#### 9.4.2 日志

日志可以帮助我们查看是否有人曾经利用系统漏洞进行恶意攻击。

不应该将敏感信息放在日志中。

#### 9.4.3 入侵检测（和预防）系统

区别于防火墙，IDS和IPS是在可信范围内积极寻找可疑行为。

#### 9.4.4 网络隔离

可以把服务放进不同的网段，以进一步控制服务间的通信。

#### 9.4.5 操作系统

及时做好操作系统的补丁升级。

### 9.5 一个示例

一个细粒度的架构，在安全实施上给了我们更多的自由。对于那些处理最敏感信息的，或暴露最有价值的功能的部分，我们可以采用最严格的安全措施。但对系统的其他部分，我们可以采用宽松一些的安全措施。

### 9.6 保持节俭

是否有必要保存所有的信息。如果不存储他们，就没有人能偷走，也没有人能索取它。

### 9.7 人的因素

当组织中的人离开组织时，如何撤销访问凭证。如何保护自己不受社会工程学的攻击。

### 9.8 黄金法则

再次强调，不要实现自己的加密算法。

### 9.9 内建安全

帮助培养开发人员的安全意识很关键，提高每个人对安全问题的普遍意识，有助于从最开始减少这些问题。

[Open Web Application Security Project (OWASP)](https://www.owasp.org)定期更新的十大安全风险文档，应被视为所有开发人员的必备读物。

[微软的安全开发生命周期](https://www.microsoft.com/en-us/sdl/default.aspx)有一些很好的模型来帮助交付团队内建安全。

### 9.10 外部验证

请外部团队来进行安全评估的价值很大。

### 9.11 小结

微服务不仅可能会减少任何安全破坏的影响，它还给予我们更多的能力对敏感数据的情况，采取开销更大、更复杂和更安全的方案，而当风险低时，采用更轻量级的方案。

第10章 康威定律和系统设计
---------------------

康威定律：梅尔.康威于1968年4月在Datamation杂志上发表了一篇名为“How Do Committees Invent”的论文，文中指出：

> 任何组织在设计一套系统（广义概念上的系统）时，所交付的设计方案在结构上都与该组织的沟通结构保持一致。

### 10.1 证据

#### 10.1.1 松耦合组织和紧耦合组织

组织的耦合度越低，创建的系统的模块化就越好，耦合也越低；组织的耦合度越高，其创建的系统的模块化也越差。

#### 10.1.2 Windows Vista

微软对它的一个特定产品Windows Vista进行了实证研究（ http://research.microsoft.com/pubs/70535/tr-2008-11.pdf ）[ [1](https://www.microsoft.com/en-us/research/publication/the-influence-of-organizational-structure-on-software-quality-an-empirical-case-study/)]，观察其自身组织结构如何影响软件质量。

### 10.2 Netflix和Amazon

在早期，Amazon就理解了，团队对他们所管理系统的整个生命周期负责的好处。小团队比大团队工作更有效。

### 10.3 我们可以做什么

看看每种情况对我们的系统设计可能产生的影响。

### 10.4 适应沟通途径

一个团队如果分处异地，则可能会导致沟通效率下降，从而导致很难进行细粒度的沟通。考虑如何将一些接缝拆出来交给另一个地域的团队去做，可能会更有效。

### 10.5 服务所有权

所有权程度的增加会提高自治和交付速度。团队需要自己负责部署和维护应用程序，这会激励团队创建出易于部署的服务。

### 10.6 共享服务的原因

#### 10.6.1 难以分割

很显然，拆分服务的成本太高是多个团队负责单个服务的原因之一。

#### 10.6.2 特性团队

一个小团队负责开发一系列特性需要的所有功能，即使这些功能需要跨越组件（甚至服务）的边界。

服务会根据业务领域而不是技术进行建模。要尽量避免出现技术导向的团队。

#### 10.6.3 交付瓶颈

如果某个服务新增了大量的需求，在不共享服务的情况下，我们可以：

- 等待，等待后端服务做完了再处理前端，但会带来交付的延期。

- 加人，只有采用标准的技术栈才能使用这种方法。

- 拆分服务

### 10.7 内部开源

#### 10.7.1 守护者的角色

有一个守护者负责某个服务的代码，并审核Pull请求。

好的守护者会花费大量的精力与提交者进行清晰的沟通，并对他们的工作方式进行引导。糟糕的守护者会以此为借口，向别人发号施令，或施加类似宗教战争般固执的技术决策。无论哪种，都需要时间。

#### 10.7.2 成熟

成熟的服务才适合开源并让其他人贡献代码。

#### 10.7.3 工具

分布式版本工具是内部开源所需要的。有时候甚至还可能需要支持讨论和修改提交申请的工具。

### 10.8 限界上下文和团队结构

我们以限界上下文来定义服务的边界，也希望团队与限界上下文保持一致。

### 10.9 孤儿服务

有一些服务一旦写完就很久都不会变动，这样的服务就像无人守护的孤儿。保持与限界上下文一致的团队结构，也有利地保证了孤儿服务也有人负责维护。

### 10.10 案例研究：RealEstate.com.au

例子中：一个业务线内，服务间可以不受任何限制地以任何方式来通信，只要团队确定的服务守护者认为合适即可。但是在业务线之间，所有通信都必须是异步批处理，这是非常小的架构团队的几个严格的规则之一。这种粗粒度的通信与不同业务之间的粗粒度的通信是匹配的。坚持异步处理，每条业务线在自身的行为和管理上有很大的自由度。它可以随时停止其服务，只要能满足其他业务线的批量集成，以及自己业务干系人的需求，那么没有人会在意。

### 10.11 反向的康威定律

可以调整组织结构来适应系统，则称为反向的康威定律，它也能很好地工作。

### 10.12 人

每个组织都有自己的节奏。了解你的员工能够承受的变化，不要逼他们改变太快！

### 10.13 小结

当限界上下文与组织结构不匹配的时候，就会产生那些摩擦点，保持两者的匹配非常重要。

第11章 规模化微服务
---------------------

### 11.1 故障无处不在

规模化后，故障将成为必然事件。那么需要假定故障一定会发生，再设计系统，将会使系统更佳健壮。

### 11.2 多少是太多

响应时间/延迟、可用性、数据持久性，这些你都得定量，然后可能需要对他们进行持续测量，甚至在生产监控。你必须思考多少才是你真正需要的。

### 11.3 功能降级

我们需要做的是理解每个故障的影响，并弄清楚如何恰当地降级功能。

### 11.4 架构性安全措施

有一些模式组合起来被称为架构性安全措施，它们可以确保如果事情真的出错了，不会引起严重的级联影响。

强烈建议在系统中将它们标准化，以确保不会因为一个服务的问题导致整个系统的崩塌。

### 11.5 反脆弱的组织

尝试进行各种各样的灾难演练，仍然保证系统的正常。如Google的[DiRT](http://queue.acm.org/detail.cfm?id=2371516)，它甚至模拟地震等大规模的自然灾害。

Netflix不仅通过让软件拥抱和引发故障，并构建系统来应对，它还知道当失败发生后从失败中学习的重要性，并在错误真正发生时采用不指责文化。

#### 11.5.1 超时

给所有的跨进程调用设置超时，并选择一个默认的超时时间。当超时发生后，记录到日志里看看发生了什么，并相应地调整它们。

#### 11.5.2 断路器

使用断路器时，当对下游资源的请求发生一定数量的失败后，断路器会打开。接下来，所有的请求再断路器打开的状态下，会快速失败。一段时间后，客户端发送一些请求查看下游服务是否已经恢复，如果它得到了正常的响应，将重置断路器。

#### 11.5.3 舱壁

舱壁（bulkhead），是把自己从故障中隔离开的一种方式。

[Netflix的Hystrix库](https://github.com/Netflix/Hystrix)(Java)、[.NET的Polly库](https://github.com/App-vNext/Polly)(.NET)、[circuit_breaker mixin](https://github.com/wsargent/circuit_breaker)(Ruby)都是现成的实现了舱壁的类库。

#### 11.5.4 隔离

一个服务越依赖另一个，另一个服务的健康就越能影响其正常工作的能力。如果我们使用的集成技术允许下游服务器离线，上游服务便不太可能受到计划内或计划外宕机的影响。

### 11.6 幂等

设计系统的时候，将系统设计成幂等的，这种幂等通常是表示一种业务状态，而不是整个系统状态，对应的日志等信息仍然会改变系统，但是重复调用，不会影响业务计算。比如，两次调用对同一个订单增加积分的操作，如果被设计成幂等，不论调用几次，都只会增加一次积分，但是会增加多次日志。

在HTTP协议中，GET和PUT被定义为幂等的，但是需要对应的程序也按幂等的方式实现，否则，我们将无法实现幂等，同时还会给调用者带来困扰。

### 11.7 扩展

#### 11.7.1 更强大的主机

提升机器硬件通常可以改善延迟和提升吞吐量，但是价格很贵。这种扩展最大的问题是，程序本身必须充分利用好这些多出来的CPU和内存，否则改善有限。

#### 11.7.2 拆分负载

因为微服务是通过网络通信的独立进程，所以把它们切换到使用自己的主机来提高吞吐量和伸缩性，应该是一件很容易的事。这还可以增加系统的弹性，因为单台主机的宕机将影响较少数量的服务。

#### 11.7.3 分散风险

在不同的主机上面运行，在不同的数据中心运行，在不同的供应商提供的云上运行，都将分散风险。

#### 11.7.4 负载均衡

负载均衡的外部可以使用HTTPS，而内部可以使用HTTP（SSL终端负载均衡器）。

#### 11.7.5 基于worker的系统

使用worker的系统可能和负载均衡一样有效。它还能利用闲时进行一些其他的计算工作，比如生成报表等。

#### 11.7.6 重新设计

Jeff Dean说：你的设计应该考虑10倍容量的增长，但超过100倍容量时就要重写了。

需要更改我们的系统来应对规模化，这不是失败的标志，而是成功的标志。

### 11.8 扩展数据库

#### 11.8.1 服务的可用性和数据的持久性

使用副本数据库可以在主数据库挂掉的时候，提升副本数据库。

#### 11.8.2 扩展读取

读写分离，可能会存在短时间的不一致情况，程序如果能够有效处理不一致的情况，这是一个相当简单和常见的用来扩展系统的方式。

几年前这种方式非常风靡，但现在可以考虑缓存技术来改善性能。

#### 11.8.3 扩展写操作

采用分片技术来，对数据的关键字进行哈希计算，并确定它应该被分到哪一片。但是写入分片可能会扩展写容量，但不会提高弹性。

#### 11.8.4 共享数据库基础设施

在一个正在运行的数据库可以承载多个独立的模式，每个微服务一个。但是这样就引入了单点故障，需要保证数据库本身有很好的弹性才能避免单点故障。

#### 11.8.5 CQRS

使用CQRS后，系统的 一部分负责获取修改状态的请求命令并处理它，而另一部分则负责处理查询。

这里的关键是，内部用于处理命令和查询的模型本身是完全独立的。

### 11.9 缓存

#### 11.9.1 客户端、代理和服务器端缓存

客户端缓存、代理服务器、反向代理、CDN、服务器缓存，这些都能够有效提高性能，可以混用他们。

#### 11.9.2 HTTP缓存

使用ETag、Expires和cache-control，可以告诉客户端如何缓存并且缓存多久等信息，还可以仅在资源更新的时候才进行更新。

#### 11.9.3 为写使用缓存

使用后写式缓存，可以先写入本地缓存中，并在之后的某个时刻将缓存中的数据写入下游的，可能更规范的数据源中。

#### 11.9.4 为弹性使用缓存

缓存可以在出现故障时实现弹性。比如定期抓取并生成静态页面，在系统出现故障的时候，进行响应。

#### 11.9.5 隐藏源服务

在缓存失败的时候，要能够自动填充缓存，避免将大量的请求直接抛向源服务，同时还可以让原始请求尽快失败，确保不占用资源或增加延迟。

#### 11.9.6 保持简单

缓存越多就越难评估任何数据的新鲜程度，所以要尽可能保持简单，先在一处使用缓存，在添加更多的缓存前慎重考虑。

#### 11.9.7 缓存中毒：一个警示

缓存可以很强大，但是你需要了解数据从数据源到终点的完整缓存路径，从而真正理解它的复杂性以及使它出错的原因。

### 11.10 自动伸缩

如果可以完全自动化地创建虚拟主机以及部署微服务实例。

### 11.11 CAP定理

一致性（consistency）、可用性（availability）、分区容忍性（partition tolerance），三者只能满足二者。

#### 11.11.1 牺牲一致性

系统放弃一致性以保证分区容忍性和可用性的这种做法，被称为最终一致性。

#### 11.11.2 牺牲可用性

如果我们需要保证一致性，就要放弃其他方面。但是保持一致性太难了，可以使用一些工具，如Consul设计实现了一个强一致性的键值存储，在多个节点之间共享配置。

#### 11.11.3 牺牲分区容忍性

在分布式系统中不存在没有分区容忍性的系统，因为一旦牺牲了它，它将不再是分布式系统。

#### 11.11.4 AP还是CP

AP系统扩展更容易，而且构建更简单。

CP系统由于要支持分布式一致性会遇到更多挑战，需要更多的工作。

#### 11.11.5 这不是全部或全不

系统可以被设计成既有CP也有AP的，以满足不同业务的不同需要。

#### 11.11.6 真实世界

有些时候，一些不一致性并不来自系统，而是系统以外的真实世界，比如某个商品库存，可能因为商品在仓库中损坏，但是系统中并不知道，这些最终仍然会导致系统的不一致性，因此大多数时候，保证AP，则更容易应对这些问题。

### 11.12 服务发现

DNS是广为人知并被广泛支持的。但它确实有一两个缺点。建议在采用更复杂的方案之前，调查一下它是否适合你。

当你只有单个节点时，使用DNS直接引用主机就可以了。但对于那些有多个主机实例的情况，应该将DNS条目解析到负载均衡器，它可以正确地把单个主机移入和移出服务。

### 11.13 动态服务注册

#### 11.13.1 ZooKeeper

ZooKeeper的核心是提供了一个用于存储信息的分层命名空间。

可以认为它只是信息树的一个副本，当它发生更改时对你做出提醒。

#### 11.13.2 Consul

[Consul](http://www.consul.io/)比ZooKeeper更进一步，为这些关键是用场景提供了更多支持。它为服务发现提供了一个HTTP接口，而且还提供了现成的DNS服务，还可以做一些健康检查等。

#### 11.13.4 构造你自己的系统

构建自己的系统并在服务发生变化的时候收到通知。

#### 11.13.5 别忘了人

生成报表或仪表盘，让人看到这些服务发现和注册的内容。

### 11.14 文档服务

#### 11.14.1 Swagger

[Swagger](http://swagger.io)让你描述API，产生一个很友好的Web用户界面。

#### 11.14.2 HAL和HAL浏览器

如果你已经使用了超媒体控制，则建议使用HAL，否则可能还需要修改API来支持HAL，那么可能更推荐Swagger。

### 11.15 自描述系统

[人文注册表](http://martinfowler.com/bliki/HumaneRegistry.html)，可以让人们记录组织中有关服务的信息，和维基一样简单。

### 11.16 小结

作者推荐Nygard的优秀图书[Release It！](https://www.amazon.cn/发布-软件的设计与部署-尼加德/dp/B00SRO01GY/ref=sr_1_1?ie=UTF8&qid=1479659648&sr=8-1&keywords=Release+It)。这本书分享了一系列关于系统故障的故事，以及一些处理它们的模式。

第12章 总结
---------------------

### 12.1 微服务的原则

作者建议同时使用以下所有的原则，舍弃任何一条的同时，请确保你明白其带来的损失。

#### 12.1.1 围绕业务概念建模

使用限界上下文来定义可能的领域边界。

#### 12.1.2 接受自动化文化

微服务引入了很多的复杂性，使用自动化测试、自动化部署、持续集成、持续交付、自定义镜像等技术，来保持正确性。

#### 12.1.3 隐藏内部实现细节

为了使一个服务独立于其他服务，最大化独自演化的能力，隐藏实现细节至关重要。

使用数据泵（data pump）或事件数据泵（event data pump），将跨多个服务的数据整合到一起，以实现报表的功能。

在可能的情况下，尽量选择与技术无关的API，这能让你自由选择使用不同的技术栈，比如REST。

#### 12.1.4 让一切都去中心化

让团队和组织保持一致，从而使康威定律起作用。

像企业服务总线或服务编配系统这样的方案，会导致业务逻辑的中心化或哑服务，应该避免使用它们。使用协同来代替编排或哑中间件，使用智能端点（smart endpoint）确保相关的逻辑和数据，在服务限界内能保持服务的内聚性。

#### 12.1.5 可独立部署

我们应该始终努力确保微服务可以独立部署。

加快新功能的发布速度。

#### 12.1.6 隔离失败

避免级联故障带来的问题，才能避免系统比以前更加脆弱。不要像使用本地调用那样处理远程调用。

#### 12.1.7 高度可观察

从整体上看待系统正在发生的事情。

### 12.2 什么时候你不应该使用微服务

- 在不了解一个业务领域的时候，也就是你无法很好地划分限界上下文的时候，先去弄清楚这个领域。

- 从头开始就构建微服务，不一定合适，相反，先构建单块系统再拆分微服务，相对容易。

当微服务规模化以后，需要花时间来构建工具和实践，帮助管理微服务。所以，构建微服务应该是逐步进行的过程。

### 12.3 临别赠言

逐步演进系统，缩小决策的范围，可以避免在推进微服务的过程中出错，并将决策错误缩小到最小。要习惯采用演进式架构的概念，在不断的学习新东西之后扩展和变化。